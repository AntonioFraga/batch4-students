{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU10 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "import hashlib # for grading purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q0: Create the ratings matrix (ungraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'ml-latest-small', 'ratings.csv')\n",
    "data = pd.read_csv(path)\n",
    "# Shuffle Data\n",
    "data = data.sample(10493, random_state=200)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we'll ignore the _timestamp_ and use the _rating_ column as our only source of information for our recommender system. Remember that if you had data of other types of interactions between users and the movies, you could create a metric that incorporates all of that information in the ratings matrix (maybe by averaging them).\n",
    "\n",
    "Keep the following ratings matrix schema in your mind while developing non-personalized systems. These systems rely heavily on the ratings matrix, so maybe also write it on a piece of paper to remember it better!\n",
    "\n",
    "<img align=\"left\" width=\"413\" height=\"239\" src=\"./media/ratings_matrix3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise you will build the ratings matrix with users as rows and products as columns.\n",
    "\n",
    "Tip: you can use the pandas' _pivot_ function or flex your numpy muscles with the _genfromtxt_ function (it is good for your health!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a6b8634bc3ef2ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_ratings(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        data - the original data with ratings per user and product.\n",
    "        \n",
    "    Returns:\n",
    "        R - (numpy.ndarray) Ratings matrix with the userId, movieId and rating\n",
    "        hint: don't forget to put zeros on places where you do not have ratings\n",
    "    \n",
    "    Extra Hint: Your input is a pandas DataFrame but you want to output an array (use .to_numpy)!\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "\n",
    "R = make_ratings(data)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"We have {R.shape[0]} user and {R.shape[1]} items.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96e5374618fa4f16",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '0825c15053e635376af0a569e8f37cfaef0e1dfce37ae6878517e14e061f13c4'\n",
    "assert hashlib.sha256(str(R.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash_1 = '8ab31b5afaea56114427e1f01b81d001b079a0f59539f6db3f099816ca794055'\n",
    "assert hashlib.sha256(str(R[0].sum()).encode()).hexdigest() == expected_hash_1\n",
    "\n",
    "expected_hash_2 = 'b5967724d1225caa9c6af28a9b333a29e6d5c11a24e9d381acf5c3377524b776'\n",
    "assert hashlib.sha256(str(R[:,0].sum()).encode()).hexdigest() == expected_hash_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Convert the Ratings Matrix to a Sparse Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, convert the ratings matrix to a sparse representation - use any method you want. \n",
    "\n",
    "Hint: Remember what we have done with scipy library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0c272ba37054416",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_csr(R):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        R - The original Ratings Matrix.\n",
    "    \n",
    "    Returns\n",
    "        H_ - The Compressed Sparse Row Matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "H_ = get_csr(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-35b3a4b1f0a76185",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'b265829173d9fab7c76766a5e089cf84879d0bdcbf61aa51146afd659b291fc3'\n",
    "assert hashlib.sha256(str(H_).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: What is the space efficiency of converting to sparse?\n",
    "\n",
    "In this exercise, let's understand how much space we save (this is, the percentage of rows that are zero in the original rating matrix).\n",
    "\n",
    "Calculate that % in the get sparsity score function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49adf0f3c0101526",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_sparsity_score(R):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        R - Ratings Matrix\n",
    "        \n",
    "    Returns:\n",
    "        sparsity_score - (float) Sparsity Score of R. In percentage, rounded up to 2 decimal places.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "sparsity_score = get_sparsity_score(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0792440f45999d40",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '19385d6767a3ff1e11ffa2a5521c3b1a5dfcb0cfd6cdb9a172155e690f9404d5'\n",
    "assert hashlib.sha256(str(sparsity_score).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"The Sparsity Score is {sparsity_score}%.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Popular Items - What are the Top-3 Most Rated items?\n",
    "More ratings give us the current trends but not necessarily the best suggestions - but let's check Items that have more ratings given.\n",
    "\n",
    "In this exercise you will have to retrieve the indexes of the products so you may need to recreate the ratings matrix as a dataframe or come up with another creative solution!\n",
    "\n",
    "**Hint: To get the ID's it's easier if you work with data frames as rating matrixes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9ce05dd01331575e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top3items(R, n=3):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        R - Ratings matrix\n",
    "        n - Number of Top-n items to retrieve\n",
    "        \n",
    "    Returns\n",
    "        most_rated - (list) list of product ids of  \n",
    "        the top-n most rated items\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "most_wanted = top3items(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ae4661f44fc09de8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '3f54e8a66e4924557721acdcb1d40e4399376f780ce6d2b11f48931fc5e1376f'\n",
    "assert hashlib.sha256(str(most_wanted).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Influencers - What are the Top-5 Most Active Users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1559bfc72b8eaf4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_influencers(R, n=5):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        R - Ratings matrix\n",
    "        n - number of top-n most active users\n",
    "        \n",
    "    Returns\n",
    "        influencers - (list) list of \n",
    "        ids of the top-n most active users\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return top_ids\n",
    "\n",
    "influencers = get_influencers(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2cd4b77837e74779",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '1879949fb971e59003fafcd4ee77e7a49d4e103d630b4fa2b38ce4268634f1e7'\n",
    "assert hashlib.sha256(str(influencers).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Elite - What are the Top-7 Better Rated Items (On Average)?\n",
    "\n",
    "Since this can be biased by a low number of ratings, we need items to have at least 10 ratings. Use average to obtain the ids of the top average rated products.\n",
    "\n",
    "Hint: In this exercise and to filter the movies by rating, it may be easier to use the original data and then reconstruct the ratings matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62b63f8f75bd5d58",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def elite(data, n=7, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        data - The original ratings.\n",
    "        n - Top-n items\n",
    "        k - Mininum number of ratings\n",
    "        \n",
    "    Returns\n",
    "        best_items - (numpy.ndarray) array for top-n best mean rated items.\n",
    "                     Your indices should refer only to items with more than k ratings (subset of original matrix).\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    \n",
    "best_items = elite(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3e673279793bc5d4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '0ed83bd0067fb63b2c591d0039829a3a9bc6887a7bb8f076bc15f6e6944e9216'\n",
    "assert hashlib.sha256(str(best_items).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Apriori - What are the 4 most common 2-piece itemsets?\n",
    "We define \"common itemsets\" as at least 2 different items that are usually rated together at least by 0.5% of the population (erheeem support!).\n",
    "Show your results sorted by support in descending way.\n",
    "\n",
    "Hint: Check the mlxtend documentation for help: http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dff47ecd831f9ca3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def getBundlesSolution(data, n=None, min_support=None, top=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        R: Ratings Matrix\n",
    "        n: Number of items in commonset\n",
    "        min_support: Minimum percentage of users that contains the itemset\n",
    "        top: Number of most common itemsets\n",
    "        \n",
    "    Return\n",
    "        df: the return dataframe should have two columns [\"support\", \"itemsets\"],\n",
    "            with the support percentage and the itemsets.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "\n",
    "df = getBundlesSolution(data, n=2, min_support=0.005, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-404e9c98f711743d",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'f7441550a0ca5274581d023417c99540e3a8a4cca68824a87cbe6d95c07742ea'\n",
    "assert hashlib.sha256(str(df.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '9278d41b216e936c8ac0bcb11af99bad893ebfd9679886766e8dba86e3d335cf'\n",
    "assert hashlib.sha256(str(df.iloc[0,1]).encode()).hexdigest() == expected_hash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
